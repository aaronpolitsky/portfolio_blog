[
  {
    "objectID": "posts/hawaii_data_collaborative/index.html",
    "href": "posts/hawaii_data_collaborative/index.html",
    "title": "Hawai’i Data Collaborative Project",
    "section": "",
    "text": "Head over to Hawai’i Data Collaborative site to view the archived interactive dashboards.\nFor example:\n                    \nI’ll write more about the behind-the-scenes when I get some free time."
  },
  {
    "objectID": "posts/dunkbonds/index.html",
    "href": "posts/dunkbonds/index.html",
    "title": "DUNKbonds",
    "section": "",
    "text": "I built dunkbonds.com for people who wanted to declare a personal goal and then challenge friends and family to bet on whether they’d succeed, with the losing bets going to charity. Its namesake goal was my quest to dunk a basketball for the first time on a regulation hoop by February 28, 2013 (at age 34).\n“DUNKbonds” is of course a play on junk bonds, which carry real risk of defaulting. If you bought a DUNKbond from me and I didn’t meet my goal, I would pay you back in full. But if I dunked in time, it was like I “defaulted” on the bond, and I’d give your money to charity. And if you bought or sold a bond on the secondary market, that price reflected the market’ opinion on whether I’d succeed.\nIn other words, it was a philanthropic prediction market for personal goals. Goalsetters would get accountability, motivation, and a “market view” on the confidence of their audience. Market participants would have some fun trying to be right, all in the name of charity.\nIn true procrastinator fashion, I dunked on the very last day before my deadline. I was more surprised than anyone.\nThis being a coding blog, I’ll run through some of the technical aspects below."
  },
  {
    "objectID": "posts/dunkbonds/index.html#overview",
    "href": "posts/dunkbonds/index.html#overview",
    "title": "DUNKbonds",
    "section": "",
    "text": "I built dunkbonds.com for people who wanted to declare a personal goal and then challenge friends and family to bet on whether they’d succeed, with the losing bets going to charity. Its namesake goal was my quest to dunk a basketball for the first time on a regulation hoop by February 28, 2013 (at age 34).\n“DUNKbonds” is of course a play on junk bonds, which carry real risk of defaulting. If you bought a DUNKbond from me and I didn’t meet my goal, I would pay you back in full. But if I dunked in time, it was like I “defaulted” on the bond, and I’d give your money to charity. And if you bought or sold a bond on the secondary market, that price reflected the market’ opinion on whether I’d succeed.\nIn other words, it was a philanthropic prediction market for personal goals. Goalsetters would get accountability, motivation, and a “market view” on the confidence of their audience. Market participants would have some fun trying to be right, all in the name of charity.\nIn true procrastinator fashion, I dunked on the very last day before my deadline. I was more surprised than anyone.\nThis being a coding blog, I’ll run through some of the technical aspects below."
  },
  {
    "objectID": "posts/dunkbonds/index.html#technical-overview",
    "href": "posts/dunkbonds/index.html#technical-overview",
    "title": "DUNKbonds",
    "section": "Technical Overview",
    "text": "Technical Overview\n\nOn Ruby on Rails\nI had no web development experience, so after asking around, I landed on Ruby on Rails. I liked that it was opinionated and structured, and if you didn’t try to go against the grain, it made things pretty easy. My background had been in compiled languages like C, C++, as well as the hardware language Verilog, so with Ruby being an interpreted language, it seemed wildly easier to write. I bought a used macbook and got started.\n\n\nModel Object Structure and Features\nThe site is a Rails app in which Goalsetters (really just a special case of User) can create Goals, which other users can Follow, and if they so choose, buy or sell its Bonds. Each Goal has its own blog (remember those?), which are the main way Followers can learn about and stay current with the goal. Users would follow Goals and open Accounts with a goal through which they can buy and sell Bonds.\nSome of the features were simple, like setting up follow relationships, which I learned during a rails tutorial.\nOther features took a little more thought, but were fairly commonplace, like setting up guest user functionality, so you didn’t have to sign up with the site until after you poked around for a while.\nBut far and away the biggest challenge was the bond market. This was bespoke. I would have loved to find some prebuilt library functionality or an example on the web, but most e-commerce solutions at the time were simply for outright buying things and completing the sale, rather than for setting up a two-sided market where bids and asks could sit for a while. So I had to build my own. Keep in mind this was when I was working in semiconductors, well before I switched to financial regulation. My only finance knowledge came from having read Michael Lewis’ The Big Short.\nBehind the scenes I stood up a rudimentary Bond market for each Goal, complete with shopping Carts, order books, a trade wizard, and an escrow account of sorts.\nOn the blogging functionality, I and other Goalsetters would blog using third party blogging tools (I used Blogger, now defunct) to author and store the actual blog post contents. The site would watch those sites, periodically pull in the blog content into Post objects in the database, then display them in the site.\nI’ll update this with more when I get some more time."
  },
  {
    "objectID": "posts/fantasy_football_luck/index.html",
    "href": "posts/fantasy_football_luck/index.html",
    "title": "Coming Soon: Fantasy Football Schedule Luck",
    "section": "",
    "text": "Coming soon.\nI need to dust off the old code (base R!), so i’ll be a minute, but the gist is:"
  },
  {
    "objectID": "posts/fantasy_football_luck/index.html#intro",
    "href": "posts/fantasy_football_luck/index.html#intro",
    "title": "Coming Soon: Fantasy Football Schedule Luck",
    "section": "Intro",
    "text": "Intro\nMost fantasy football leagues use a head-to-head format, basing playoff berths on win-loss records. Meaning, every week of the regular season, your fantasy team goes up against another participant’s team, and whichever team scored more points gets the win. At the end of the regular season, your head-to-head win-loss record determines whether you make the playoffs. I’m simplifying of course, but the win-loss record is typically the chief determinant of playoff berth.\nUnder this format, it’s quite common for your team to have a low scoring week but still eke out a win because your opponent’s team had an even lower score. On the flipside, you may have had the second highest score for the week, but you faced the team with the highest score. Contrary to real football, your fantasy football opponent’s team has basically no bearing on how well your team performs. By and large you are trying for the highest score1, so your opponent is basically interchangeable. So it’s legitimate to claim that your record may have been meaningfully better (or worse) had your regular season schedule been different.\nI wondered how my league’s results might have been different under different schedules, so I set out to measure the impact scheduling had on playoff berths over the years by simulating alternate schedules and analyzing the distribution of results.\nI found …"
  },
  {
    "objectID": "posts/fantasy_football_luck/index.html#the-plan-resimulate-league-history-with-alternate-schedules",
    "href": "posts/fantasy_football_luck/index.html#the-plan-resimulate-league-history-with-alternate-schedules",
    "title": "Coming Soon: Fantasy Football Schedule Luck",
    "section": "The Plan: Resimulate League History with Alternate Schedules",
    "text": "The Plan: Resimulate League History with Alternate Schedules\n\nI scraped my ESPN fantasy league’s 13-season history, saving each team’s weekly points in a csv.\nThen I re-simulated every season a million times, taking each owner’s weekly score as given, but randomizing the season’s head to head schedules.\nWith the simulation results we can explore owners’ win-loss distributions, their expected win rates, and see who got lucky or unlucky in a given year, and if any participants have enjoyed persistent luckiness over the years.\nI find that schedule plays a huge role in determining playoff berth and that using an all-play schedule format (where you play every other team each week) would mitigate this."
  },
  {
    "objectID": "posts/fantasy_football_luck/index.html#reading-the-league-history",
    "href": "posts/fantasy_football_luck/index.html#reading-the-league-history",
    "title": "Coming Soon: Fantasy Football Schedule Luck",
    "section": "Reading the League History",
    "text": "Reading the League History\n… (when I get to it)"
  },
  {
    "objectID": "posts/fantasy_football_luck/index.html#footnotes",
    "href": "posts/fantasy_football_luck/index.html#footnotes",
    "title": "Coming Soon: Fantasy Football Schedule Luck",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI acknowledge that in a given week you might start a lower risk-reward player if you expect to win the matchup, and vice versa if you are the underdog. But I would argue this is only important on the margin and that job one is to maximize expected points.↩︎"
  },
  {
    "objectID": "posts/purrr_for_data_validation/index.html",
    "href": "posts/purrr_for_data_validation/index.html",
    "title": "Purrr for Data Validation",
    "section": "",
    "text": "This post explains an insight I had when thinking about a data validation problem, and I hope this example problem will get you thinking more creatively about the possibilities of nested tibbles. (If you’re not familiar with the nested data workflow, read this this concise article first, and for more depth, read this chapter of R4DS. I’ll wait.)\nOK, Great. Now you’re at least somewhat familiar with the nested data workflow. That is, grouping your data and nesting each group’s data into cells in a column called “data”. You wind up with a Tidy, summarized tibble with one row per group so you can work with the nested data as a if it were a single value in a cell.\nBut did you ever think of nesting source code into a cell? If you’re at all curious about how or why this might be a good idea, keep reading.\nMy specific problem required running a bunch of data validation tests on a dataset, and I wanted to neatly keep track of the tests, their code, and their results. This reminded me of the nested data workflow, but instead of iterating over groups of data, I wanted to iterate over a group of validation functions. My insight was to nest each test’s source code into the tibble, execute each test on the data, and nest its results into another column, leaving me with a single, Tidy tibble having the test names, their code, and their results.\nBut why do it this way? Couldn’t you use base R using several separate lists and a vector of test names to access them? Sure, but I prefer having all this in one table. When everything is neatly tied together in rows it’s less error prone. Plus it’s Tidy, so it will be easy to work with later using the typical tidyverse methods.\nWhereas using separate lists, it’s up to you to keep everything straight since the lists aren’t aware of one another. Someone (such as future me) could come along and accidentally rename the elements of one of the lists without updating the others, and it would fail quietly.\nLet’s motivate this solution with an example problem."
  },
  {
    "objectID": "posts/purrr_for_data_validation/index.html#example-data",
    "href": "posts/purrr_for_data_validation/index.html#example-data",
    "title": "Purrr for Data Validation",
    "section": "Example Data",
    "text": "Example Data\nI’ll use iris as the example dataset. It’s got four decimal fields and one factor field per observation.\n\n\n# A tibble: 150 × 6\n   id    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n   &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1 1              5.1         3.5          1.4         0.2 setosa \n 2 2              4.9         3            1.4         0.2 setosa \n 3 3              4.7         3.2          1.3         0.2 setosa \n 4 4              4.6         3.1          1.5         0.2 setosa \n 5 5              5           3.6          1.4         0.2 setosa \n 6 6              5.4         3.9          1.7         0.4 setosa \n 7 7              4.6         3.4          1.4         0.3 setosa \n 8 8              5           3.4          1.5         0.2 setosa \n 9 9              4.4         2.9          1.4         0.2 setosa \n10 10             4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows"
  },
  {
    "objectID": "posts/purrr_for_data_validation/index.html#the-field-test-catalog",
    "href": "posts/purrr_for_data_validation/index.html#the-field-test-catalog",
    "title": "Purrr for Data Validation",
    "section": "The Field-Test Catalog",
    "text": "The Field-Test Catalog\nAs I thought about the problem, it became clear that I would want to define a set of validation tests for each field and keep track of the field-test catalog in a list or a table structure.\nThe catalog of field-tests might look something like this:\n\n\n\nField Name\nTest Name\n\n\n\n\nSepal.Length\nis_missing\n\n\nSepal.Length\nis_not_between_3_and_7\n\n\nSepal.Length\nis_less_than_sepal_width\n\n\n…\n…\n\n\nSepal.Width\nis_missing\n\n\nSepal.Width\n…\n\n\n…\n…\n\n\nPetal.Length\nis_missing\n\n\nPetal.Length\nis_not_between_4_and_7_when_species_is_virginica\n\n\n…"
  },
  {
    "objectID": "posts/purrr_for_data_validation/index.html#desired-output-form",
    "href": "posts/purrr_for_data_validation/index.html#desired-output-form",
    "title": "Purrr for Data Validation",
    "section": "Desired Output Form",
    "text": "Desired Output Form\nI wanted to generate a set of results for each field-test that I could tie back to individual observations in the data. Results for one particular field’s test would look like this:\n\n\n\nId\nResult\n\n\n\n\n1\nFALSE\n\n\n2\nFALSE\n\n\n…\n…\n\n\n149\nTRUE\n\n\n150\nFALSE\n\n\n\nThis is of course not very useful without knowing its corresponding field and test, so an expanded, flat set of results might look like this:\n\n\n\n\n\n\n\n\n\nField\nTest\nId\nResult\n\n\n\n\nSepal.Length\nis_missing\n1\nTRUE\n\n\nSepal.Length\nis_missing\n2\nFALSE\n\n\nSepal.Length\nis_missing\n…\n…\n\n\nSepal.Length\nis_missing\n138\nTRUE\n\n\n…\n\n\n\n\n\nPetal.Width\nis_not_between_4_and_7_when_species_is_virginica\n32\nNA\n\n\n…\n\n\n\n\n\nPetal.Width\nis_not_between_4_and_7_when_species_is_virginica\n138\nFALSE\n\n\n…\n\n\n\n\n\nSpecies\nis_not_within_known_set\n1\nTRUE\n\n\n…\n…\n\n\n\n\n\nThe objects I would need to keep track of included:\n\nthe field-test catalog\neach field-test’s source code, parameters, and description\neach field-test’s results\nand the iris_tbl dataset itself\n\nThis smelled like the nested data workflow, but inverted. Rather than mapping one function to a group of datasets, I would feed one dataset to a group of functions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aaron’s Data Science and Coding Blog",
    "section": "",
    "text": "Welcome!\nI want to get some of my coding thoughts out into the world, so this is a sort of code portfolio in blog form.\nI really enjoy the Posit/RStudio workflows, as well as coding in R, so I used Quarto to build this.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHawai’i Data Collaborative Project\n\n\nIn 2018-19 I worked on a data visualization consulting project with Hawai’i Data Collaborative, to design and implement interactive dashboard visualizations of Well Being metrics.\n\n\n\nR\n\n\nTableau\n\n\ndata visualization\n\n\ninteractivity\n\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nAaron Politsky\n\n\n\n\n\n\n\n\n\n\n\n\nDUNKbonds\n\n\nAbout the Rails app I built back in 2012-2013 as a prediction market for personal goals, where losing bets would go to charity. \n\n\n\nruby on rails\n\n\nweb development\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nAaron Politsky\n\n\n\n\n\n\n\n\n\n\n\n\nPurrr for Data Validation\n\n\nOr: Nesting Functions Into a Tibble\n\n\n\ndata science\n\n\nfunctional programming\n\n\npurrr\n\n\nnested tibbles\n\n\nR\n\n\n\nTidyverse R enthusiasts know about nesting grouped data into a column and iterating using purrr::map(), but did you know you could nest function source code? This post uses a data validation example to explain how I used this nest-and-iterate pattern over a set of validation tests while keeping the tests, their code, and their results in one Tidy tibble.\n\n\n\n\n\nFeb 11, 2024\n\n\nAaron Politsky\n\n\n\n\n\n\n\n\n\n\n\n\nComing Soon: Fantasy Football Schedule Luck\n\n\nMeasuring the Impact of Head-to-Head Schedules on Playoff Berths\n\n\n\ndata science\n\n\n\nYour fantasy team put up a ton of points over the season, yet you missed the playoffs because your opponents always had their best weeks against you. How would your season have gone if you had a different schedule? I re-simulate 15 years of league history to quantify how un/lucky my league’s participants have been and to measure how much making the playoffs depends on schedule. (Spolier: a LOT!)\n\n\n\n\n\nFeb 11, 2024\n\n\nAaron Politsky\n\n\n\n\n\n\nNo matching items"
  }
]